{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import math\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import learning_curve,GridSearchCV\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset:\n",
      "(146811, 3)\n",
      "Column names:\n",
      "Index(['review_id', 'review', 'rating'], dtype='object')\n",
      "Datatype of each column:\n",
      "review_id     int64\n",
      "review       object\n",
      "rating        int64\n",
      "dtype: object\n",
      "Few dataset entries:\n",
      "   review_id                                             review  rating\n",
      "0          0  Ga disappointed neat products .. Meletot Hilsn...       1\n",
      "1          1    Rdtanya replace broken glass, broken chargernya       1\n",
      "2          2  Nyesel bngt dsni shopping antecedent photo mes...       1\n",
      "3          3      Sent a light blue suit goods ga want a refund       1\n",
      "4          4  Pendants came with dents and scratches on its ...       1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>146811.000000</td>\n",
       "      <td>146811</td>\n",
       "      <td>146811.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>115328</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Excellent product quality</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1378</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>73405.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.562764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>42380.829522</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.260537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>36702.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>73405.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>110107.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>146810.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            review_id                      review         rating\n",
       "count   146811.000000                      146811  146811.000000\n",
       "unique            NaN                      115328            NaN\n",
       "top               NaN   Excellent product quality            NaN\n",
       "freq              NaN                        1378            NaN\n",
       "mean     73405.000000                         NaN       3.562764\n",
       "std      42380.829522                         NaN       1.260537\n",
       "min          0.000000                         NaN       1.000000\n",
       "25%      36702.500000                         NaN       3.000000\n",
       "50%      73405.000000                         NaN       4.000000\n",
       "75%     110107.500000                         NaN       5.000000\n",
       "max     146810.000000                         NaN       5.000000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LOADING THE DATASET AND SEEING THE DETAILS\n",
    "data = pd.read_csv('train.csv')\n",
    "# SHAPE OF THE DATASET\n",
    "print(\"Shape of the dataset:\")\n",
    "print(data.shape)\n",
    "# COLUMN NAMES\n",
    "print(\"Column names:\")\n",
    "print(data.columns)\n",
    "# DATATYPE OF EACH COLUMN\n",
    "print(\"Datatype of each column:\")\n",
    "print(data.dtypes)\n",
    "# SEEING FEW OF THE ENTRIES\n",
    "print(\"Few dataset entries:\")\n",
    "print(data.head())\n",
    "# DATASET SUMMARY\n",
    "data.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Ga disappointed neat products .. Meletot Hilsn...\n",
      "1      Rdtanya replace broken glass, broken chargernya\n",
      "2    Nyesel bngt dsni shopping antecedent photo mes...\n",
      "3        Sent a light blue suit goods ga want a refund\n",
      "4    Pendants came with dents and scratches on its ...\n",
      "Name: review, dtype: object\n",
      "0    1\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "Name: rating, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Seperate the dataset into X and Y for prediction\n",
    "x = data['review']\n",
    "y = data['rating']\n",
    "print(x.head())\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLEANING THE REVIEWS - REMOVAL OF STOPWORDS AND PUNCTUATION\n",
    "def text_process(text):\n",
    "    nopunc = [char for char in text if char not in string.punctuation]\n",
    "    nopunc = ''.join(nopunc)\n",
    "    return [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94887\n",
      "Ga disappointed neat products .. Meletot Hilsnyaa Speed ​​of delivery is good.\n",
      "  (0, 10608)\t1\n",
      "  (0, 11917)\t1\n",
      "  (0, 16363)\t1\n",
      "  (0, 23219)\t1\n",
      "  (0, 40513)\t1\n",
      "  (0, 42138)\t1\n",
      "  (0, 47581)\t1\n",
      "  (0, 63453)\t1\n",
      "  (0, 71212)\t1\n",
      "  (0, 90055)\t1\n",
      "Getting the words back:\n",
      "Pit\n",
      "Gak\n"
     ]
    }
   ],
   "source": [
    "vocab = CountVectorizer(analyzer=text_process).fit(x)\n",
    "print(len(vocab.vocabulary_))\n",
    "r0 = x[0]\n",
    "print(r0)\n",
    "vocab0 = vocab.transform([r0])\n",
    "print(vocab0)\n",
    "print(\"Getting the words back:\")\n",
    "print(vocab.get_feature_names()[19648])\n",
    "print(vocab.get_feature_names()[10643])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the sparse matrix:  (146811, 94887)\n",
      "Non-Zero occurences:  1326688\n",
      "Density of the matrix =  0.009523651352382709\n"
     ]
    }
   ],
   "source": [
    "x = vocab.transform(x)\n",
    "#Shape of the matrix:\n",
    "print(\"Shape of the sparse matrix: \", x.shape)\n",
    "#Non-zero occurences:\n",
    "print(\"Non-Zero occurences: \",x.nnz)\n",
    "\n",
    "# DENSITY OF THE MATRIX\n",
    "density = (x.nnz/(x.shape[0]*x.shape[1]))*100\n",
    "print(\"Density of the matrix = \",density)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPLITTING THE DATASET INTO TRAINING SET AND TESTING SET\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Multinomial Naive Bayes:\n",
      "[[1747  147  777  146  184]\n",
      " [ 575  387 1199  178  150]\n",
      " [ 456  268 4340  899 1121]\n",
      " [ 216  176 1460 3065 3598]\n",
      " [ 221  174 1396 2954 3529]]\n",
      "Score: 44.5\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.58      0.56      3001\n",
      "           2       0.34      0.16      0.21      2489\n",
      "           3       0.47      0.61      0.53      7084\n",
      "           4       0.42      0.36      0.39      8515\n",
      "           5       0.41      0.43      0.42      8274\n",
      "\n",
      "    accuracy                           0.45     29363\n",
      "   macro avg       0.44      0.43      0.42     29363\n",
      "weighted avg       0.44      0.45      0.44     29363\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Multinomial Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(x_train,y_train)\n",
    "predmnb = mnb.predict(x_test)\n",
    "print(\"Confusion Matrix for Multinomial Naive Bayes:\")\n",
    "print(confusion_matrix(y_test,predmnb))\n",
    "print(\"Score:\",round(accuracy_score(y_test,predmnb)*100,2))\n",
    "print(\"Classification Report:\",classification_report(y_test,predmnb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Random Forest Classifier:\n",
      "[[1757  240  639  203  162]\n",
      " [ 548  607  919  212  203]\n",
      " [ 512  271 4255  975 1071]\n",
      " [ 260   86 1404 3424 3341]\n",
      " [ 257   75 1342 3347 3253]]\n",
      "Score: 45.28\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.59      0.55      3001\n",
      "           2       0.47      0.24      0.32      2489\n",
      "           3       0.50      0.60      0.54      7084\n",
      "           4       0.42      0.40      0.41      8515\n",
      "           5       0.41      0.39      0.40      8274\n",
      "\n",
      "    accuracy                           0.45     29363\n",
      "   macro avg       0.46      0.45      0.45     29363\n",
      "weighted avg       0.45      0.45      0.45     29363\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rmfr = RandomForestClassifier()\n",
    "rmfr.fit(x_train,y_train)\n",
    "predrmfr = rmfr.predict(x_test)\n",
    "print(\"Confusion Matrix for Random Forest Classifier:\")\n",
    "print(confusion_matrix(y_test,predrmfr))\n",
    "print(\"Score:\",round(accuracy_score(y_test,predrmfr)*100,2))\n",
    "print(\"Classification Report:\",classification_report(y_test,predrmfr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Decision Tree:\n",
      "[[1473  371  615  287  255]\n",
      " [ 492  741  686  275  295]\n",
      " [ 613  562 3574 1142 1193]\n",
      " [ 366  246 1493 3315 3095]\n",
      " [ 356  241 1506 3197 2974]]\n",
      "Score: 41.13\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.45      0.49      0.47      3001\n",
      "           2       0.34      0.30      0.32      2489\n",
      "           3       0.45      0.50      0.48      7084\n",
      "           4       0.40      0.39      0.40      8515\n",
      "           5       0.38      0.36      0.37      8274\n",
      "\n",
      "    accuracy                           0.41     29363\n",
      "   macro avg       0.41      0.41      0.41     29363\n",
      "weighted avg       0.41      0.41      0.41     29363\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(x_train,y_train)\n",
    "preddt = dt.predict(x_test)\n",
    "print(\"Confusion Matrix for Decision Tree:\")\n",
    "print(confusion_matrix(y_test,preddt))\n",
    "print(\"Score:\",round(accuracy_score(y_test,preddt)*100,2))\n",
    "print(\"Classification Report:\",classification_report(y_test,preddt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Support Vector Machines:\n",
      "[[1869   43  673  263  153]\n",
      " [ 570  481 1058  195  185]\n",
      " [ 417  131 4501 1052  983]\n",
      " [ 157   21 1255 3691 3391]\n",
      " [ 173   22 1196 3584 3299]]\n",
      "Score: 47.14\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.62      0.60      3001\n",
      "           2       0.69      0.19      0.30      2489\n",
      "           3       0.52      0.64      0.57      7084\n",
      "           4       0.42      0.43      0.43      8515\n",
      "           5       0.41      0.40      0.41      8274\n",
      "\n",
      "    accuracy                           0.47     29363\n",
      "   macro avg       0.53      0.46      0.46     29363\n",
      "weighted avg       0.48      0.47      0.46     29363\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machine\n",
    "from sklearn.svm import SVC\n",
    "svm = SVC(random_state=101)\n",
    "svm.fit(x_train,y_train)\n",
    "predsvm = svm.predict(x_test)\n",
    "print(\"Confusion Matrix for Support Vector Machines:\")\n",
    "print(confusion_matrix(y_test,predsvm))\n",
    "print(\"Score:\",round(accuracy_score(y_test,predsvm)*100,2))\n",
    "print(\"Classification Report:\",classification_report(y_test,predsvm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-76358281b4ef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m#Boosting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mgbi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGradientBoostingClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m999999\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mgbi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0mpredgbi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgbi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Confusion Matrix for Gradient Boosting Classifier:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m   1535\u001b[0m         n_stages = self._fit_stages(\n\u001b[0;32m   1536\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_rng\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1537\u001b[1;33m             sample_weight_val, begin_at_stage, monitor, X_idx_sorted)\n\u001b[0m\u001b[0;32m   1538\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1539\u001b[0m         \u001b[1;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[1;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1592\u001b[0m             raw_predictions = self._fit_stage(\n\u001b[0;32m   1593\u001b[0m                 \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1594\u001b[1;33m                 random_state, X_idx_sorted, X_csc, X_csr)\n\u001b[0m\u001b[0;32m   1595\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1596\u001b[0m             \u001b[1;31m# track deviance (= loss)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[1;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_idx_sorted, X_csc, X_csr)\u001b[0m\n\u001b[0;32m   1243\u001b[0m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1244\u001b[0m             tree.fit(X, residual, sample_weight=sample_weight,\n\u001b[1;32m-> 1245\u001b[1;33m                      check_input=False, X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m   1246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1247\u001b[0m             \u001b[1;31m# update tree leaves\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1223\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1224\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1225\u001b[1;33m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m   1226\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1227\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    365\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    366\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 367\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    369\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Gradient Boosting Classifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\"\"\"# parameter evaluation\n",
    "gbe = GradientBoostingClassifier(random_state=0)\n",
    "parameters = {\n",
    "     'learning_rate': [0.05, 0.1, 0.5],\n",
    "    'max_features': [0.5, 1],\n",
    "    'max_depth': [3, 4, 5]}\n",
    "gridsearch=GridSearchCV(gbe,parameters,cv=100,scoring='roc_auc')\n",
    "gridsearch.fit(x,y)\n",
    "print(gridsearch.best_params_)\n",
    "print(gridsearch.best_score_)\"\"\"\n",
    "#Boosting\n",
    "gbi = GradientBoostingClassifier(learning_rate=0.1,max_depth=5,max_features=0.5,random_state=999999)\n",
    "gbi.fit(x_train,y_train)\n",
    "predgbi = gbi.predict(x_test)\n",
    "print(\"Confusion Matrix for Gradient Boosting Classifier:\")\n",
    "print(confusion_matrix(y_test,predgbi))\n",
    "print(\"Score:\",round(accuracy_score(y_test,predgbi)*100,2))\n",
    "print(\"Classification Report:\",classification_report(y_test,predgbi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for K Neighbors Classifier:\n",
      "[[1546  351  577  288  239]\n",
      " [ 619  703  676  267  224]\n",
      " [ 827  560 3694 1121  882]\n",
      " [ 572  286 1823 3144 2690]\n",
      " [ 537  293 1711 3156 2577]]\n",
      "Score:  39.72\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      0.52      0.44      3001\n",
      "           2       0.32      0.28      0.30      2489\n",
      "           3       0.44      0.52      0.47      7084\n",
      "           4       0.39      0.37      0.38      8515\n",
      "           5       0.39      0.31      0.35      8274\n",
      "\n",
      "    accuracy                           0.40     29363\n",
      "   macro avg       0.38      0.40      0.39     29363\n",
      "weighted avg       0.39      0.40      0.39     29363\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# K Nearest Neighbour Algorithm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=10)\n",
    "knn.fit(x_train,y_train)\n",
    "predknn = knn.predict(x_test)\n",
    "print(\"Confusion Matrix for K Neighbors Classifier:\")\n",
    "print(confusion_matrix(y_test,predknn))\n",
    "print(\"Score: \",round(accuracy_score(y_test,predknn)*100,2))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test,predknn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for XGBoost Classifier:\n",
      "[[ 745   26  649 1412  169]\n",
      " [ 183  409  758  987  152]\n",
      " [ 144   85 3811 2372  672]\n",
      " [  67   14 1315 4369 2750]\n",
      " [  72   17 1259 4197 2729]]\n",
      "Score:  41.08\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.25      0.35      3001\n",
      "           2       0.74      0.16      0.27      2489\n",
      "           3       0.49      0.54      0.51      7084\n",
      "           4       0.33      0.51      0.40      8515\n",
      "           5       0.42      0.33      0.37      8274\n",
      "\n",
      "    accuracy                           0.41     29363\n",
      "   macro avg       0.52      0.36      0.38     29363\n",
      "weighted avg       0.46      0.41      0.40     29363\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# XGBoost Classifier\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(x_train,y_train)\n",
    "predxgb = xgb.predict(x_test)\n",
    "print(\"Confusion Matrix for XGBoost Classifier:\")\n",
    "print(confusion_matrix(y_test,predxgb))\n",
    "print(\"Score: \",round(accuracy_score(y_test,predxgb)*100,2))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test,predxgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MULTILAYER PERCEPTRON CLASSIFIER\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier()\n",
    "mlp.fit(x_train,y_train)\n",
    "predmlp = mlp.predict(x_test)\n",
    "print(\"Confusion Matrix for Multilayer Perceptron Classifier:\")\n",
    "print(confusion_matrix(y_test,predmlp))\n",
    "print(\"Score:\",round(accuracy_score(y_test,predmlp)*100,2))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test,predmlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ga disappointed neat products .. Meletot Hilsnyaa Speed ​​of delivery is good.\n",
      "Actual Rating:  1\n",
      "Predicted Rating:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing model\n",
    "\n",
    "pr = data['review'][0]\n",
    "print(pr)\n",
    "print(\"Actual Rating: \",data['rating'][0])\n",
    "pr_t = vocab.transform([pr])\n",
    "print(\"Predicted Rating:\")\n",
    "svm.predict(pr_t)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Great danger, cool, motif and cantik2 jg model...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>One of the shades don't fit well</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Very comfortable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Fast delivery. Product expiry is on Dec 2022. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>it's sooooo cute! i like playing with the glit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_id                                             review\n",
       "0          1  Great danger, cool, motif and cantik2 jg model...\n",
       "1          2                   One of the shades don't fit well\n",
       "2          3                                   Very comfortable\n",
       "3          4  Fast delivery. Product expiry is on Dec 2022. ...\n",
       "4          5  it's sooooo cute! i like playing with the glit..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading test set\n",
    "\n",
    "testing = pd.read_csv(\"test.csv\")\n",
    "testing.head()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Great danger, cool, motif and cantik2 jg model...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>One of the shades don't fit well</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Very comfortable</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Fast delivery. Product expiry is on Dec 2022. ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>it's sooooo cute! i like playing with the glit...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_id                                             review rating\n",
       "0          1  Great danger, cool, motif and cantik2 jg model...       \n",
       "1          2                   One of the shades don't fit well       \n",
       "2          3                                   Very comfortable       \n",
       "3          4  Fast delivery. Product expiry is on Dec 2022. ...       \n",
       "4          5  it's sooooo cute! i like playing with the glit...       "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding new column\n",
    "\n",
    "testing['rating'] = \"\"\n",
    "testing.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andy_uni\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "# Using the best model to predict the rating for the test set\n",
    "\n",
    "for index,row in testing.iterrows():\n",
    "    pr = testing['review'][index]\n",
    "    pr_t = vocab.transform([pr])\n",
    "    testing['rating'][index]= rmfr.predict(pr_t)[0]\n",
    "    \n",
    "    if index % 10000 ==0:\n",
    "        print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing=testing.drop(['review'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing.to_csv(r'C:\\Users\\Andy_uni\\Desktop\\submission(rmfr).csv', index = False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
